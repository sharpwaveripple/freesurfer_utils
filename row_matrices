#!/usr/bin/env python 

import os
import argparse
import numpy as np
import pandas as pd
import nibabel as nib


def num_seeds(seed_mask_path):
    seed_mask = nib.load(seed_mask_path).get_data()
    n_seeds = np.count_nonzero(seed_mask)
    return n_seeds

def probtrack_output(track_dir, omat=2):
    coords_path = os.path.join(track_dir,
                               f'tract_space_coords_for_fdt_matrix{omat}')
    dotmat_path = os.path.join(track_dir,
                               f'fdt_matrix{omat}.dot')
    coords = pd.read_csv(coords_path, delim_whitespace=True,
                         names=['x', 'y', 'z'])
    coords['location'] = list(zip(coords.x, coords.y, coords.z))
    dotmat = pd.read_csv(dotmat_path, delim_whitespace=True,
                         names=['seed', 'target', 'samples'])
    return coords, dotmat

def get_basename(fpath):
    base = os.path.basename(fpath)
    first = os.path.splitext(base)[0]
    second = os.path.splitext(first)[0]
    return second

def desikan_dict():
    home = os.path.expanduser('~')
    dk_file = os.path.join(home, 'bin/freesurfer_utils/info/desikan.txt')
    desikan = pd.read_csv(dk_file, index_col='Num').to_dict()
    desikan_dict = desikan['Name']
    return desikan_dict

def map_labels(targ_vox, coord_tup, parc):
    unique_vox = np.unique(targ_vox)
    location = coord_tup[unique_vox - 1]   # Subtract 1 for 0-based indexing
    label_ind = np.array([parc[point] for point in location])
    return label_ind

def filter_labels(valid_labels, label_ind):
    unique_labels = np.unique(label_ind)
    filtered_labels = [x for x in unique_labels if x in valid_labels]
    return filtered_labels

def parse_input():
    parser = argparse.ArgumentParser()
    parser.add_argument("--bedpost_dir", type=str, required=True, metavar="",
                        help="bedpostX directory with probtrackX results")
    parser.add_argument("--fs_dir", type=str, required=True, metavar="",
                        help="Processed FreeSurfer directory")
    parser.add_argument("--roi_name", type=str, required=True, metavar="",
                        help="ROI name (e.g. lh.bankssts)")
    parser.add_argument("--omatrix", type=int, default=2, metavar="",
                        help="omatrix integer setting for probtrackX")
    # parser.add_argument("--parc", type=str, default="aparc", metavar="",
    #                     help="Parcellation scheme (default: aparc)")
    args = parser.parse_args()
    return args

def io_stream():
    args = parse_input()
    args.parc = 'aparc'
    labels = desikan_dict()  # generalize this
    roi = os.path.join(args.fs_dir, f'{args.parc}_roi/{args.roi_name}.nii.gz')
    seed_size = num_seeds(roi)
    norm_factor = seed_size * 5000
    results_folder = os.path.join(args.bedpost_dir, args.roi_name)
    coords, dotmat = probtrack_output(results_folder)
    parc_file = os.path.join(args.fs_dir, f'mri/{args.parc}+aseg.mgz')
    parc = nib.load(parc_file).get_data()
    label_map = map_labels(dotmat['target'], coords['location'], parc)
    row_vector = []
    for label in labels.keys():
        label_ind = np.where(label_map == label)[0]
        if len(label_ind) == 0:
            row_vector.append('0')
        else:
            n_samples = np.sum(dotmat['samples'][label_ind])
            weighted_samples = (n_samples / norm_factor) * 100
            weighted_samples = np.round(weighted_samples, 2)
            row_vector.append(str(weighted_samples))
    row_vector = ' '.join(row_vector)
    out_file = os.path.join(args.bedpost_dir, f'{args.roi_name}.txt')
    with open(out_file, 'w+') as f:
        f.write(row_vector)
        f.write('\n')


if __name__ == "__main__":
    io_stream()
